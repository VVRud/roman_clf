{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:23:44.104721Z",
     "start_time": "2019-02-06T15:23:42.898214Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "sys.path.extend(['..'])\n",
    "\n",
    "from utils.config import process_config\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.layers import (conv2d, max_pooling2d, average_pooling2d, batch_normalization, dropout, dense)\n",
    "from tensorflow.nn import (relu, sigmoid, softmax, leaky_relu)\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:23:44.263448Z",
     "start_time": "2019-02-06T15:23:44.261258Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA = '../data/data_clean/'\n",
    "CONF = '../configs/roman.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:23:44.494977Z",
     "start_time": "2019-02-06T15:23:44.490631Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "def shuffle_sim(a, b):\n",
    "    assert a.shape[0] == a.shape[0], 'Shapes must be equal'\n",
    "    \n",
    "    ind = np.arange(a.shape[0])\n",
    "    np.random.shuffle(ind)\n",
    "    return a[ind], b[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:23:44.587275Z",
     "start_time": "2019-02-06T15:23:44.579358Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_train_test(path_to_data):\n",
    "    data = {}\n",
    "    for dset in ['train', 'test']:\n",
    "        path_ = os.path.join(path_to_data, dset)\n",
    "        X, Y = [], []\n",
    "        classes = [d for d in os.listdir(path_) if os.path.isdir(os.path.join(path_, d))]\n",
    "        classes.sort()\n",
    "        \n",
    "        for cl in classes:\n",
    "            y = np.zeros((1, 8), dtype=np.int32)\n",
    "            y[0, int(cl) - 1] = 1\n",
    "            \n",
    "            cl_path = os.path.join(path_, cl)\n",
    "            filenames = [os.path.join(cl_path, pict) for pict in os.listdir(cl_path) if pict.endswith('.jpg')]\n",
    "            \n",
    "            for im in filenames:\n",
    "                image = np.asarray(Image.open(im), dtype=np.float32)\n",
    "                X.append(normalize(image).reshape((1, image.shape[0], image.shape[1], image.shape[2])))\n",
    "                Y.append(y)\n",
    "        \n",
    "        a, b = shuffle_sim(np.concatenate(X), np.concatenate(Y))\n",
    "        data[dset] = ([a, b])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:41:20.793642Z",
     "start_time": "2019-02-06T15:41:20.769986Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \n",
    "    def __init__(self, config, sess_cf, learning_rate):\n",
    "        self.lr = learning_rate\n",
    "        self.sess = tf.Session(config=sess_cf)\n",
    "\n",
    "        self.x = tf.placeholder(dtype=tf.float32, shape=(None, config.image_size, config.image_size, 3))\n",
    "        self.y = tf.placeholder(dtype=tf.int32, shape=(None, 8))\n",
    "        self.training = tf.placeholder(dtype=tf.bool, shape=())\n",
    "\n",
    "        global_step = tf.Variable(1, name='global_step', trainable=False, dtype=tf.int32)\n",
    "        self.step = tf.assign(global_step, global_step + 1)\n",
    "        \n",
    "        self.model()\n",
    "        \n",
    "        self.summ_writer = tf.summary.FileWriter(config.summary_dir, graph=self.sess.graph)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def block(self, inp,\n",
    "              ch,\n",
    "              num,\n",
    "              c_ker=[(3, 3), (3, 3)],\n",
    "              c_str=[(1, 1), (1, 1)],\n",
    "              act=relu,\n",
    "              mp_ker=(2, 2),\n",
    "              mp_str=(2, 2)):\n",
    "    \n",
    "        with tf.variable_scope('block_' + str(num), reuse=tf.AUTO_REUSE):\n",
    "            conv = conv2d(inp, ch, c_ker[0], strides=c_str[0])\n",
    "            bn = batch_normalization(conv)\n",
    "            out = act(bn)\n",
    "            out = dropout(out, 0.2)\n",
    "            tf.summary.histogram('conv1', conv)\n",
    "            print(out.shape)\n",
    "            \n",
    "            conv = conv2d(out, ch, c_ker[1], strides=c_str[1])\n",
    "            bn = batch_normalization(conv)\n",
    "            out = act(bn)\n",
    "            tf.summary.histogram('conv2', conv)\n",
    "            print(out.shape)\n",
    "            \n",
    "            out = max_pooling2d(out, mp_ker, strides=mp_str)\n",
    "            print(out.shape)\n",
    "        return out\n",
    "    \n",
    "    def model(self):\n",
    "        with tf.name_scope('layers'):\n",
    "            out = self.block(self.x, 32, 1, c_str=[(1, 1), (1, 1)])\n",
    "            out = self.block(out, 64, 2, c_str=[(1, 1), (1, 1)])\n",
    "            out = self.block(out, 128, 3, c_str=[(1, 1), (1, 1)])\n",
    "            out = self.block(out, 256, 4, c_str=[(1, 1), (2, 2)])\n",
    "            \n",
    "            dim = np.prod(out.shape[1:])\n",
    "            out = tf.reshape(out, [-1, dim])\n",
    "            print(out.shape)\n",
    "            \n",
    "            dense_l = dense(out, 128)\n",
    "            tf.summary.histogram('dense2', dense_l)\n",
    "            out = batch_normalization(dense_l)\n",
    "            out = leaky_relu(out, alpha=0.01)\n",
    "            out = dropout(out, rate=0.7, training=self.training)\n",
    "            print(out.shape)\n",
    "\n",
    "            self.predictions = dense(out, 8, activation=softmax)\n",
    "            tf.summary.histogram('pred', self.predictions)\n",
    "\n",
    "        with tf.name_scope('metrics'):    \n",
    "            amax_labels = tf.argmax(self.y, 1)\n",
    "            amax_pred   = tf.argmax(self.predictions, 1)\n",
    "\n",
    "            self.loss = tf.losses.softmax_cross_entropy(self.y, self.predictions)        \n",
    "            self.acc = tf.reduce_mean(tf.cast(tf.equal(amax_labels, amax_pred), dtype=tf.float32))\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            tf.summary.scalar('accuracy', self.acc)\n",
    "\n",
    "        self.summary = tf.summary.merge_all()\n",
    "        \n",
    "    def train(self, dat, dat_v, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            loss, acc, _, summary, step = self.sess.run([\n",
    "                self.loss, self.acc, self.optimizer, self.summary, self.step\n",
    "            ],\n",
    "                                                feed_dict={\n",
    "                                                    self.x: dat[0],\n",
    "                                                    self.y: dat[1],\n",
    "                                                    self.training: True\n",
    "                                                })\n",
    "\n",
    "            self.summ_writer.add_summary(summary, step)\n",
    "            print('EP: {:3d}\\tLOSS: {:.10f}\\tACC: {:.10f}'.format(\n",
    "                epoch, loss, acc))\n",
    "\n",
    "            if epoch % 10 == 0 and epoch != 0:\n",
    "                self.test(dat_v)\n",
    "                \n",
    "    def test(self, dat):\n",
    "        loss, acc = self.sess.run([self.loss, self.acc],\n",
    "                                         feed_dict={self.x: dat[0],\n",
    "                                                    self.y: dat[1],\n",
    "                                                    self.training: False})\n",
    "\n",
    "        print('\\tVALIDATION\\tLOSS: {:.10f}\\tACC: {:.10f}'.format(loss, acc))\n",
    "    \n",
    "    def close(self):\n",
    "        self.sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:41:21.936076Z",
     "start_time": "2019-02-06T15:41:21.933404Z"
    }
   },
   "outputs": [],
   "source": [
    "m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:41:23.976897Z",
     "start_time": "2019-02-06T15:41:23.973740Z"
    }
   },
   "outputs": [],
   "source": [
    "config_tf = tf.ConfigProto(allow_soft_placement=True)\n",
    "config_tf.gpu_options.allow_growth = True\n",
    "config_tf.gpu_options.per_process_gpu_memory_fraction = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:41:29.404054Z",
     "start_time": "2019-02-06T15:41:29.400294Z"
    }
   },
   "outputs": [],
   "source": [
    "config = process_config(CONF)\n",
    "config['exp_name'] = '4b_mf_1'\n",
    "config['summary_dir'] = '../experiments/' + config['exp_name'] + '/summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:41:32.008602Z",
     "start_time": "2019-02-06T15:41:30.529697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 126, 126, 32)\n",
      "(?, 124, 124, 32)\n",
      "(?, 62, 62, 32)\n",
      "(?, 60, 60, 64)\n",
      "(?, 58, 58, 64)\n",
      "(?, 29, 29, 64)\n",
      "(?, 27, 27, 128)\n",
      "(?, 25, 25, 128)\n",
      "(?, 12, 12, 128)\n",
      "(?, 10, 10, 256)\n",
      "(?, 4, 4, 256)\n",
      "(?, 2, 2, 256)\n",
      "(?, 1024)\n",
      "(?, 128)\n"
     ]
    }
   ],
   "source": [
    "m = Model(config, config_tf, 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:41:40.862688Z",
     "start_time": "2019-02-06T15:41:40.417784Z"
    }
   },
   "outputs": [],
   "source": [
    "dat = read_train_test(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-06T16:24:58.598Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:   0\tLOSS: 1.3219293356\tACC: 0.9501084685\n",
      "EP:   1\tLOSS: 1.3271000385\tACC: 0.9479392767\n",
      "EP:   2\tLOSS: 1.3127039671\tACC: 0.9587852359\n",
      "EP:   3\tLOSS: 1.3346115351\tACC: 0.9414316416\n",
      "EP:   4\tLOSS: 1.3258922100\tACC: 0.9479392767\n",
      "EP:   5\tLOSS: 1.3181246519\tACC: 0.9587852359\n",
      "EP:   6\tLOSS: 1.3139684200\tACC: 0.9609544277\n",
      "EP:   7\tLOSS: 1.3143208027\tACC: 0.9631236196\n",
      "EP:   8\tLOSS: 1.3184775114\tACC: 0.9544468522\n",
      "EP:   9\tLOSS: 1.3273341656\tACC: 0.9436008930\n",
      "EP:  10\tLOSS: 1.3233304024\tACC: 0.9544468522\n",
      "\tVALIDATION\tLOSS: 1.4170440435\tACC: 0.8666666746\n",
      "EP:  11\tLOSS: 1.3253732920\tACC: 0.9479392767\n",
      "EP:  12\tLOSS: 1.3310130835\tACC: 0.9457700849\n",
      "EP:  13\tLOSS: 1.3330909014\tACC: 0.9370932579\n",
      "EP:  14\tLOSS: 1.3196415901\tACC: 0.9544468522\n",
      "EP:  15\tLOSS: 1.3373776674\tACC: 0.9370932579\n",
      "EP:  16\tLOSS: 1.3284895420\tACC: 0.9436008930\n",
      "EP:  17\tLOSS: 1.3238655329\tACC: 0.9544468522\n",
      "EP:  18\tLOSS: 1.3218891621\tACC: 0.9501084685\n",
      "EP:  19\tLOSS: 1.3318897486\tACC: 0.9414316416\n",
      "EP:  20\tLOSS: 1.3308130503\tACC: 0.9414316416\n",
      "\tVALIDATION\tLOSS: 1.4460037947\tACC: 0.8249999881\n",
      "EP:  21\tLOSS: 1.3114334345\tACC: 0.9609544277\n",
      "EP:  22\tLOSS: 1.3129820824\tACC: 0.9609544277\n",
      "EP:  23\tLOSS: 1.3257842064\tACC: 0.9479392767\n",
      "EP:  24\tLOSS: 1.3320213556\tACC: 0.9436008930\n",
      "EP:  25\tLOSS: 1.3195821047\tACC: 0.9566160440\n",
      "EP:  26\tLOSS: 1.3261619806\tACC: 0.9479392767\n",
      "EP:  27\tLOSS: 1.3267430067\tACC: 0.9457700849\n",
      "EP:  28\tLOSS: 1.3240929842\tACC: 0.9501084685\n",
      "EP:  29\tLOSS: 1.3139023781\tACC: 0.9652928710\n",
      "EP:  30\tLOSS: 1.3209027052\tACC: 0.9587852359\n",
      "\tVALIDATION\tLOSS: 1.4603120089\tACC: 0.8166666627\n",
      "EP:  31\tLOSS: 1.3258776665\tACC: 0.9501084685\n",
      "EP:  32\tLOSS: 1.3197727203\tACC: 0.9566160440\n",
      "EP:  33\tLOSS: 1.3337968588\tACC: 0.9392624497\n",
      "EP:  34\tLOSS: 1.3299258947\tACC: 0.9436008930\n",
      "EP:  35\tLOSS: 1.3295744658\tACC: 0.9457700849\n",
      "EP:  36\tLOSS: 1.3344080448\tACC: 0.9370932579\n",
      "EP:  37\tLOSS: 1.3270674944\tACC: 0.9457700849\n",
      "EP:  38\tLOSS: 1.3276134729\tACC: 0.9479392767\n",
      "EP:  39\tLOSS: 1.3226301670\tACC: 0.9544468522\n",
      "EP:  40\tLOSS: 1.3253858089\tACC: 0.9479392767\n",
      "\tVALIDATION\tLOSS: 1.4450645447\tACC: 0.8333333135\n",
      "EP:  41\tLOSS: 1.3280084133\tACC: 0.9479392767\n",
      "EP:  42\tLOSS: 1.3322979212\tACC: 0.9457700849\n",
      "EP:  43\tLOSS: 1.3250454664\tACC: 0.9501084685\n",
      "EP:  44\tLOSS: 1.3271738291\tACC: 0.9457700849\n",
      "EP:  45\tLOSS: 1.3258289099\tACC: 0.9457700849\n",
      "EP:  46\tLOSS: 1.3268096447\tACC: 0.9436008930\n",
      "EP:  47\tLOSS: 1.3489143848\tACC: 0.9262472987\n",
      "EP:  48\tLOSS: 1.3202649355\tACC: 0.9544468522\n",
      "EP:  49\tLOSS: 1.3273342848\tACC: 0.9522776604\n",
      "EP:  50\tLOSS: 1.3042988777\tACC: 0.9696312547\n",
      "\tVALIDATION\tLOSS: 1.4685231447\tACC: 0.8000000119\n",
      "EP:  51\tLOSS: 1.3219400644\tACC: 0.9522776604\n",
      "EP:  52\tLOSS: 1.3185067177\tACC: 0.9566160440\n",
      "EP:  53\tLOSS: 1.3212591410\tACC: 0.9522776604\n",
      "EP:  54\tLOSS: 1.3243645430\tACC: 0.9479392767\n",
      "EP:  55\tLOSS: 1.3261792660\tACC: 0.9522776604\n",
      "EP:  56\tLOSS: 1.3106734753\tACC: 0.9631236196\n",
      "EP:  57\tLOSS: 1.3224728107\tACC: 0.9566160440\n",
      "EP:  58\tLOSS: 1.3097602129\tACC: 0.9631236196\n",
      "EP:  59\tLOSS: 1.3155808449\tACC: 0.9566160440\n",
      "EP:  60\tLOSS: 1.3041775227\tACC: 0.9696312547\n",
      "\tVALIDATION\tLOSS: 1.4512817860\tACC: 0.8166666627\n",
      "EP:  61\tLOSS: 1.3186951876\tACC: 0.9522776604\n",
      "EP:  62\tLOSS: 1.3110191822\tACC: 0.9631236196\n",
      "EP:  63\tLOSS: 1.3054888248\tACC: 0.9696312547\n",
      "EP:  64\tLOSS: 1.3090693951\tACC: 0.9652928710\n",
      "EP:  65\tLOSS: 1.3217847347\tACC: 0.9544468522\n",
      "EP:  66\tLOSS: 1.3116915226\tACC: 0.9609544277\n",
      "EP:  67\tLOSS: 1.3181695938\tACC: 0.9544468522\n",
      "EP:  68\tLOSS: 1.3151513338\tACC: 0.9566160440\n",
      "EP:  69\tLOSS: 1.3182605505\tACC: 0.9566160440\n",
      "EP:  70\tLOSS: 1.3274573088\tACC: 0.9479392767\n",
      "\tVALIDATION\tLOSS: 1.4713059664\tACC: 0.8000000119\n",
      "EP:  71\tLOSS: 1.3530002832\tACC: 0.9154012799\n",
      "EP:  72\tLOSS: 1.3153650761\tACC: 0.9609544277\n",
      "EP:  73\tLOSS: 1.3121329546\tACC: 0.9631236196\n",
      "EP:  74\tLOSS: 1.3182843924\tACC: 0.9587852359\n",
      "EP:  75\tLOSS: 1.3432294130\tACC: 0.9262472987\n",
      "EP:  76\tLOSS: 1.3395432234\tACC: 0.9327548742\n",
      "EP:  77\tLOSS: 1.3206043243\tACC: 0.9544468522\n",
      "EP:  78\tLOSS: 1.3098254204\tACC: 0.9631236196\n",
      "EP:  79\tLOSS: 1.3156085014\tACC: 0.9587852359\n",
      "EP:  80\tLOSS: 1.3106850386\tACC: 0.9674620628\n",
      "\tVALIDATION\tLOSS: 1.4612064362\tACC: 0.8000000119\n",
      "EP:  81\tLOSS: 1.3170584440\tACC: 0.9587852359\n",
      "EP:  82\tLOSS: 1.3193277121\tACC: 0.9566160440\n",
      "EP:  83\tLOSS: 1.3220459223\tACC: 0.9544468522\n",
      "EP:  84\tLOSS: 1.3159345388\tACC: 0.9566160440\n",
      "EP:  85\tLOSS: 1.3205845356\tACC: 0.9544468522\n",
      "EP:  86\tLOSS: 1.3138109446\tACC: 0.9587852359\n",
      "EP:  87\tLOSS: 1.3050882816\tACC: 0.9718004465\n",
      "EP:  88\tLOSS: 1.3042807579\tACC: 0.9718004465\n",
      "EP:  89\tLOSS: 1.3064990044\tACC: 0.9696312547\n",
      "EP:  90\tLOSS: 1.3065558672\tACC: 0.9696312547\n",
      "\tVALIDATION\tLOSS: 1.4556969404\tACC: 0.8083333373\n",
      "EP:  91\tLOSS: 1.3105803728\tACC: 0.9652928710\n",
      "EP:  92\tLOSS: 1.3112504482\tACC: 0.9674620628\n"
     ]
    }
   ],
   "source": [
    "m.train(dat['train'], dat['test'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
